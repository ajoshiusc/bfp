{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Difference Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ||AUM||\n",
    "import scipy.io as spio\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "from fmri_methods_sipi import hotelling_t2\n",
    "from surfproc import view_patch_vtk, patch_color_attrib, smooth_surf_function, smooth_patch\n",
    "from dfsio import readdfs\n",
    "import os\n",
    "from brainsync import normalizeData, brainSync\n",
    "from statsmodels.sandbox.stats.multicomp import fdrcorrection0 as FDR\n",
    "from sklearn.decomposition import PCA\n",
    "import csv\n",
    "\n",
    "BFPPATH = '/home/ajoshi/coding_ground/bfp'\n",
    "BrainSuitePath = '/home/ajoshi/BrainSuite17a/svreg'\n",
    "NDim = 31\n",
    "#%%\n",
    "\n",
    "p_dir = '/deneb_disk/grp_diff/ADHD_Peking_bfp'\n",
    "lst = os.listdir(p_dir)\n",
    "count1 = 0\n",
    "nsub = 0\n",
    "\n",
    "#%% Read CSV File\n",
    "normSub = [];adhdCombinedSub=[];adhdHyperactiveSub=[];adhdInattentive=[];\n",
    "with open('/deneb_disk/ADHD_Peking_bfp/Peking_all_phenotypic.csv', newline='') as csvfile:    \n",
    "    creader = csv.DictReader(csvfile, delimiter=',', quotechar='\"')\n",
    "    for row in creader:\n",
    "        dx = row['DX']\n",
    "        sub = row['ScanDir ID']\n",
    "        qc = row['QC_Rest_1']\n",
    "        fname = os.path.join(p_dir, sub + '_rest_bold.32k.GOrd.mat')\n",
    "\n",
    "        if not os.path.isfile(fname) or int(qc) != 1:\n",
    "            continue\n",
    "\n",
    "        if int(dx) == 0:\n",
    "            normSub.append(sub)\n",
    "\n",
    "        if int(dx) == 1:\n",
    "            adhdCombinedSub.append(sub)\n",
    "\n",
    "        if int(dx) == 2:\n",
    "            adhdHyperactiveSub.append(sub)\n",
    "\n",
    "        if int(dx) == 3:\n",
    "            adhdInattentive.append(sub)\n",
    "\n",
    "        print(sub, dx, qc)\n",
    "\n",
    "\n",
    "normSubOrig = normSub\n",
    "\n",
    "#%% Read Normal Subjects\n",
    "normSub = normSub[:50]\n",
    "count1 = 0\n",
    "for sub in normSub:\n",
    "    fname = os.path.join(p_dir, sub + '_rest_bold.32k.GOrd.mat')\n",
    "    df = spio.loadmat(fname)\n",
    "    data = df['dtseries'].T\n",
    "    d, _, _ = normalizeData(data)\n",
    "\n",
    "    if count1 == 0:\n",
    "        sub_data = sp.zeros((235, d.shape[1], len(normSub)))\n",
    "\n",
    "    sub_data[:, :, count1] = d[:235, ]\n",
    "    count1 += 1\n",
    "    print(count1, )\n",
    "    if count1 == 50:\n",
    "        break\n",
    "\n",
    "#%% Create Average atlas by synchronizing everyones data to one subject\n",
    "atlas = 0; q=3\n",
    "nSub = len(normSub)\n",
    "for ind in range(nSub):\n",
    "    Y2, _ = brainSync(X=sub_data[:, :, q], Y=sub_data[:, :, ind])\n",
    "    atlas += Y2\n",
    "atlas /= (nSub)\n",
    "spio.savemat('ADHD_avg_atlas.mat', {'atlas':atlas})\n",
    "\n",
    "#%% Compute PCA basis using atlas\n",
    "\n",
    "pca = PCA(n_components=NDim)\n",
    "pca.fit(atlas.T)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "\n",
    "\n",
    "#%% Read Normal Subjects\n",
    "normSub = normSubOrig[50:135]\n",
    "count1 = 0\n",
    "for sub in normSub:\n",
    "    fname = os.path.join(p_dir, sub + '_rest_bold.32k.GOrd.mat')\n",
    "    df = spio.loadmat(fname)\n",
    "    data = df['dtseries'].T\n",
    "    d, _, _ = normalizeData(data)\n",
    "    if count1 == 0:\n",
    "        sub_data = sp.zeros((235, d.shape[1], 50))\n",
    "    sub_data[:, :, count1] = d[:235,]\n",
    "    count1 += 1\n",
    "    print(count1, )\n",
    "    if count1 == 50:\n",
    "        break\n",
    "\n",
    "#%% Do PCA of Normal Controls\n",
    "#%% Atlas to normal subjects diff\n",
    "diff = sp.zeros([sub_data.shape[1],50])\n",
    "fNC = sp.zeros((NDim, sub_data.shape[1], 50))\n",
    "for ind in range(50):\n",
    "    Y2, _ = brainSync(X=atlas, Y=sub_data[:, :, ind])\n",
    "    fNC[:, :, ind] = pca.transform(Y2.T).T\n",
    "    diff[:, ind] = sp.sum((Y2 - atlas) ** 2, axis=0)\n",
    "    print(ind,)\n",
    "\n",
    "spio.savemat('ADHD_diff_avg_atlas.mat', {'diff': diff})\n",
    "\n",
    "#%% Read ADHD Inattentive\n",
    "#del sub_data\n",
    "count1 = 0\n",
    "for sub in adhdInattentive:\n",
    "    fname = os.path.join(p_dir, sub + '_rest_bold.32k.GOrd.mat')\n",
    "    df = spio.loadmat(fname)\n",
    "    data = df['dtseries'].T\n",
    "    d, _, _ = normalizeData(data)\n",
    "    if count1 == 0:\n",
    "        sub_data = sp.zeros((235, d.shape[1], 50))\n",
    "    sub_data[:, :, count1] = d[:235,]\n",
    "    count1 += 1\n",
    "    print(count1, )\n",
    "    if count1 == 50:\n",
    "        break\n",
    "\n",
    "\n",
    "#%% Atlas to normal subjects diff & Do PCA of ADHD\n",
    "diffAdhdInatt = sp.zeros([sub_data.shape[1],50])\n",
    "fADHD = sp.zeros((NDim, sub_data.shape[1], 50))\n",
    "\n",
    "for ind in range(50):\n",
    "    Y2, _ = brainSync(X=atlas, Y=sub_data[:, :, ind])\n",
    "    fADHD[:, :, ind] = pca.transform(Y2.T).T\n",
    "    diffAdhdInatt[:, ind] = sp.sum((Y2 - atlas) ** 2, axis=0)\n",
    "    print(ind,)\n",
    "\n",
    "spio.savemat('ADHD_diff_adhd_inattentive.mat', {'diffAdhdInatt': diffAdhdInatt})\n",
    "\n",
    "#%% Read surfaces for visualization\n",
    "\n",
    "lsurf = readdfs('/home/ajoshi/coding_ground/bfp/supp_data/bci32kleft.dfs')\n",
    "rsurf = readdfs('/home/ajoshi/coding_ground/bfp/supp_data/bci32kright.dfs')\n",
    "a=spio.loadmat('/home/ajoshi/coding_ground/bfp/supp_data/USCBrain_grayord_labels.mat')\n",
    "labs=a['labels']\n",
    "lsurf.attributes = np.zeros((lsurf.vertices.shape[0]))\n",
    "rsurf.attributes = np.zeros((rsurf.vertices.shape[0]))\n",
    "lsurf=smooth_patch(lsurf,iterations=1500)\n",
    "rsurf=smooth_patch(rsurf,iterations=1500)\n",
    "labs[sp.isnan(labs)]=0\n",
    "diff=diff*(labs.T>0)\n",
    "diffAdhdInatt=diffAdhdInatt*(labs.T>0)\n",
    "\n",
    "nVert = lsurf.vertices.shape[0]\n",
    "\n",
    "#%% Visualization of normal diff from the atlas\n",
    "lsurf.attributes = np.sqrt(np.sum((diff), axis=1))\n",
    "lsurf.attributes = lsurf.attributes[:nVert]/50\n",
    "rsurf.attributes = np.sqrt(np.sum((diff), axis=1))\n",
    "rsurf.attributes = rsurf.attributes[nVert:2*nVert]/50\n",
    "lsurf = patch_color_attrib(lsurf, clim=[0,.2])\n",
    "rsurf = patch_color_attrib(rsurf, clim=[0,.2])\n",
    "\n",
    "view_patch_vtk(lsurf, azimuth=100, elevation=180, roll=90,\n",
    "               outfile='l1normal.png', show=1)\n",
    "view_patch_vtk(rsurf, azimuth=-100, elevation=180, roll=-90,\n",
    "               outfile='r1normal.png', show=1)\n",
    "\n",
    "#%% Visualization of ADHD diff from the atlas\n",
    "lsurf.attributes = np.sqrt(np.sum((diffAdhdInatt), axis=1))\n",
    "lsurf.attributes = lsurf.attributes[:nVert]/50\n",
    "rsurf.attributes = np.sqrt(np.sum((diffAdhdInatt), axis=1))\n",
    "rsurf.attributes = rsurf.attributes[nVert:2*nVert]/50\n",
    "lsurf = patch_color_attrib(lsurf, clim=[0, .2])\n",
    "rsurf = patch_color_attrib(rsurf, clim=[0, .2])\n",
    "\n",
    "view_patch_vtk(lsurf, azimuth=100, elevation=180, roll=90,\n",
    "               outfile='l1adhd.png', show=1)\n",
    "view_patch_vtk(rsurf, azimuth=-100, elevation=180, roll=-90,\n",
    "               outfile='r1adhd.png', show=1)\n",
    "\n",
    "#%%\n",
    "lsurf.attributes = np.sqrt(np.sum((diffAdhdInatt), axis=1))-np.sqrt(np.sum((diff), axis=1))\n",
    "rsurf.attributes = np.sqrt(np.sum((diffAdhdInatt), axis=1))-np.sqrt(np.sum((diff), axis=1))\n",
    "lsurf.attributes = lsurf.attributes[:nVert]/50\n",
    "rsurf.attributes = rsurf.attributes[nVert:2*nVert]/50\n",
    "\n",
    "#lsurf.attributes = smooth_surf_function(lsurf,lsurf.attributes,1,1)\n",
    "#rsurf.attributes = smooth_surf_function(rsurf,rsurf.attributes,1,1)\n",
    "lsurf = patch_color_attrib(lsurf, clim=[-0.005, 0.005])\n",
    "rsurf = patch_color_attrib(rsurf, clim=[-0.005, 0.005])\n",
    "\n",
    "view_patch_vtk(lsurf, azimuth=100, elevation=180, roll=90,\n",
    "               outfile='l1adhd_normal_diff.png', show=1)\n",
    "view_patch_vtk(rsurf, azimuth=-100, elevation=180, roll=-90,\n",
    "               outfile='r1adhd_normal_diff.png', show=1)\n",
    "\n",
    "#%%\n",
    "pv = sp.zeros(diff.shape[0])\n",
    "for vind in range(diff.shape[0]):\n",
    "    _, pv[vind] = sp.stats.ranksums(diff[vind,:], diffAdhdInatt[vind,:])\n",
    "\n",
    "#%%\n",
    "\n",
    "t, pvfdr = FDR(pv[labs[0, :] > 0])\n",
    "\n",
    "lsurf.attributes = 1-pv\n",
    "rsurf.attributes = 1-pv\n",
    "lsurf.attributes = lsurf.attributes[:nVert]\n",
    "rsurf.attributes = rsurf.attributes[nVert:2*nVert]\n",
    "lsurf.attributes = smooth_surf_function(lsurf, lsurf.attributes, .3, .3)\n",
    "rsurf.attributes = smooth_surf_function(rsurf, rsurf.attributes, .3, .3)\n",
    "\n",
    "lsurf = patch_color_attrib(lsurf, clim=[0.7, 1.0])\n",
    "rsurf = patch_color_attrib(rsurf, clim=[0.7, 1.0])\n",
    "\n",
    "view_patch_vtk(lsurf, azimuth=-90, elevation=180, roll=-90,\n",
    "               outfile='l1adhd_normal_pval.png', show=1)\n",
    "view_patch_vtk(lsurf, azimuth=100, elevation=180, roll=90,\n",
    "               outfile='l2adhd_normal_pval.png', show=1)\n",
    "\n",
    "view_patch_vtk(rsurf, azimuth=90, elevation=180, roll=90,\n",
    "               outfile='r1adhd_normal_pval.png', show=1)\n",
    "view_patch_vtk(rsurf, azimuth=-100, elevation=180, roll=-90,\n",
    "               outfile='r2adhd_normal_pval.png', show=1)\n",
    "\n",
    "#%%\n",
    "\n",
    "fa = sp.transpose(fADHD, axes=[0, 2, 1])\n",
    "fc = sp.transpose(fNC, axes=[0, 2, 1])\n",
    "#fa = fa * \n",
    "#fc = fc * (labs > 0)\n",
    "labs=sp.squeeze(labs)\n",
    "pv, t2 = hotelling_t2(fa[:, :, (labs > 0)], fc[:, :, (labs > 0)])\n",
    "lsurf.attributes=sp.zeros((labs.shape[0]))\n",
    "lsurf.attributes[labs>0] = 1.0 - pv\n",
    "lsurf.attributes = smooth_surf_function(lsurf, lsurf.attributes[:nVert], 1, 1)\n",
    "lsurf = patch_color_attrib(lsurf, clim=[0.7, 1.0])\n",
    "view_patch_vtk(lsurf, azimuth=90, elevation=180, roll=90,\n",
    "               outfile='l1multiadhd_normal_pval.png', show=1)\n",
    "view_patch_vtk(lsurf, azimuth=-100, elevation=180, roll=-90,\n",
    "               outfile='l2multiadhd_normal_pval.png', show=1)\n",
    "\n",
    "rsurf.attributes = sp.zeros((labs.shape[0]))\n",
    "rsurf.attributes[labs > 0] = 1.0 - pv\n",
    "rsurf.attributes = smooth_surf_function(rsurf,\n",
    "                                        rsurf.attributes[nVert:2*nVert], 1, 1)\n",
    "rsurf = patch_color_attrib(rsurf, clim=[0.7, 1.0])\n",
    "view_patch_vtk(rsurf, azimuth=90, elevation=180, roll=90,\n",
    "               outfile='r1multiadhd_normal_pval.png', show=1)\n",
    "view_patch_vtk(rsurf, azimuth=-100, elevation=180, roll=-90,\n",
    "               outfile='r2multiadhd_normal_pval.png', show=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#%% Automatic Classification of subtypes\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
